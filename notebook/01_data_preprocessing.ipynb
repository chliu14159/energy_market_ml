{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Data Integration and Preprocessing\n",
    "\n",
    "This notebook implements the first phase of our deep learning forecasting plan. The objective is to take the raw data from the four separate CSV files, clean them, merge them into a single master dataset, and save the result for the next phase (Feature Engineering).\n",
    "\n",
    "**Steps:**\n",
    "1.  **Load Data**: Load all four CSV files into pandas DataFrames.\n",
    "2.  **Initial Cleaning**: Perform preliminary cleaning on each DataFrame, such as correcting data types, handling obvious duplicates, and dropping columns with no predictive value.\n",
    "3.  **Merge DataFrames**: Combine the four DataFrames into a single master table, using the timestamp as the primary key.\n",
    "4.  **Handle Missing Values**: Address NaNs that result from the merge or were present in the original data.\n",
    "5.  **Finalize and Save**: Set a proper time-series index, sort the data, and save the processed DataFrame to a fast, type-preserving format (`.parquet`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Define file paths\n",
    "input_dir = Path('../input')\n",
    "processed_dir = Path('../processed')\n",
    "processed_dir.mkdir(parents=True, exist_ok=True) # Ensure the output directory exists\n",
    "\n",
    "# Load the datasets\n",
    "dispatch_df = pd.read_csv(input_dir / 'DISPATCHREGIONSUM.csv')\n",
    "price_df = pd.read_csv(input_dir / 'TRADINGPRICE.csv')\n",
    "weather_df = pd.read_csv(input_dir / 'TRAINING_INDEPENDENT_INPUT.csv')\n",
    "date_dim_df = pd.read_csv(input_dir / 'DATE_DIM.csv')\n",
    "\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Clean `dispatch_df` and `price_df`\n",
    "These two files contain the core supply, demand, and price information. We will convert their timestamps to datetime objects and drop the `RUNNO` column, which has only a single value and is not useful for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispatch and Price data cleaned.\n"
     ]
    }
   ],
   "source": [
    "# Clean dispatch data\n",
    "dispatch_df['SETTLEMENTDATE'] = pd.to_datetime(dispatch_df['SETTLEMENTDATE'])\n",
    "dispatch_df = dispatch_df.drop(columns=['RUNNO'])\n",
    "\n",
    "# Clean price data\n",
    "price_df['SETTLEMENTDATE'] = pd.to_datetime(price_df['SETTLEMENTDATE'])\n",
    "# We also drop PERIODID as it's redundant with the timestamp\n",
    "price_df = price_df.drop(columns=['RUNNO', 'PERIODID'])\n",
    "\n",
    "print(\"Dispatch and Price data cleaned.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Clean `date_dim_df`\n",
    "This file contains holiday and day-type information. We need to fix the duplicate holiday column, convert the date column to datetime, and handle the many missing values in the holiday flags, which should be `False` instead of `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Dimension data cleaned.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10958 entries, 0 to 10957\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   ADJ_DATE               10958 non-null  datetime64[ns]\n",
      " 1   DAY_TYPE_QLD           10958 non-null  object        \n",
      " 2   QLD_PUBLIC_HOLIDAY     10958 non-null  bool          \n",
      " 3   TAS_PUBLIC_HOLIDAY     10958 non-null  bool          \n",
      " 4   NSW_PUBLIC_HOLIDAY     10958 non-null  bool          \n",
      " 5   VIC_PUBLIC_HOLIDAY     10958 non-null  bool          \n",
      " 6   IS_QLD_SCHOOL_HOLIDAY  10958 non-null  bool          \n",
      "dtypes: bool(5), datetime64[ns](1), object(1)\n",
      "memory usage: 224.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/2798712556.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  date_dim_df[col] = date_dim_df[col].fillna(False).astype(str).str.lower() == 'true'\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/2798712556.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  date_dim_df[col] = date_dim_df[col].fillna(False).astype(str).str.lower() == 'true'\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/2798712556.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  date_dim_df[col] = date_dim_df[col].fillna(False).astype(str).str.lower() == 'true'\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/2798712556.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  date_dim_df[col] = date_dim_df[col].fillna(False).astype(str).str.lower() == 'true'\n"
     ]
    }
   ],
   "source": [
    "# Drop the duplicate column identified in profiling\n",
    "date_dim_df = date_dim_df.drop(columns=['NSW_PUBLIC_HOLIDAY.1'])\n",
    "\n",
    "# Convert date column to datetime\n",
    "date_dim_df['ADJ_DATE'] = pd.to_datetime(date_dim_df['ADJ_DATE'])\n",
    "\n",
    "# Fill NaNs in holiday columns with False and ensure boolean type\n",
    "holiday_cols = [col for col in date_dim_df.columns if 'HOLIDAY' in col]\n",
    "for col in holiday_cols:\n",
    "    # The columns are read as object type with 'True'/'False' strings and NaNs\n",
    "    date_dim_df[col] = date_dim_df[col].fillna(False).astype(str).str.lower() == 'true'\n",
    "\n",
    "print(\"Date Dimension data cleaned.\")\n",
    "date_dim_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Clean `weather_df`\n",
    "The weather data contains many pre-calculated lag features which we will recreate ourselves later. It also has a `PV_POWER` column with over 70% missing values, which we will drop. The `STATION_NAME` is also a single-value column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data cleaned.\n"
     ]
    }
   ],
   "source": [
    "weather_df['DATE_TIME_HH'] = pd.to_datetime(weather_df['DATE_TIME_HH'])\n",
    "\n",
    "# Drop columns that are redundant, have too many NaNs, or will be re-engineered\n",
    "\n",
    "# Remove PV_POWER from cols_to_drop so it is retained\n",
    "\n",
    "cols_to_drop = [col for col in weather_df.columns if 'LAG' in col] \n",
    "cols_to_drop += ['STATION_NAME', 'YEAR', 'MONTH', 'DAY_TYPE', 'PERIOD_HH']\n",
    "\n",
    "weather_df = weather_df.drop(columns=cols_to_drop)\n",
    "\n",
    "\n",
    "# Add a flag for missing PV_POWER values\n",
    "\n",
    "weather_df['PV_POWER_MISSING'] = weather_df['PV_POWER'].isnull()\n",
    "\n",
    "print(\"Weather data cleaned.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (2099300, 27)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2099300 entries, 0 to 2099299\n",
      "Data columns (total 27 columns):\n",
      " #   Column                  Dtype         \n",
      "---  ------                  -----         \n",
      " 0   SETTLEMENTDATE          datetime64[ns]\n",
      " 1   REGIONID                object        \n",
      " 2   TOTALDEMAND             float64       \n",
      " 3   AVAILABLEGENERATION     float64       \n",
      " 4   AVAILABLELOAD           float64       \n",
      " 5   DISPATCHABLEGENERATION  float64       \n",
      " 6   DISPATCHABLELOAD        float64       \n",
      " 7   NETINTERCHANGE          float64       \n",
      " 8   INITIALSUPPLY           float64       \n",
      " 9   CLEAREDSUPPLY           float64       \n",
      " 10  RRP                     float64       \n",
      " 11  IS_WORKDAY              object        \n",
      " 12  IS_SCHOOL_HOLIDAY       object        \n",
      " 13  AIR_TEMP                float64       \n",
      " 14  HUMIDITY                float64       \n",
      " 15  DEW_POINT_TEMP          float64       \n",
      " 16  WIND_SPEED              float64       \n",
      " 17  PV_POWER                float64       \n",
      " 18  APPARENT_TEMP           float64       \n",
      " 19  IS_CALCULATED_APP_TEMP  object        \n",
      " 20  PV_POWER_MISSING        object        \n",
      " 21  DAY_TYPE_QLD            object        \n",
      " 22  QLD_PUBLIC_HOLIDAY      bool          \n",
      " 23  TAS_PUBLIC_HOLIDAY      bool          \n",
      " 24  NSW_PUBLIC_HOLIDAY      bool          \n",
      " 25  VIC_PUBLIC_HOLIDAY      bool          \n",
      " 26  IS_QLD_SCHOOL_HOLIDAY   bool          \n",
      "dtypes: bool(5), datetime64[ns](1), float64(15), object(6)\n",
      "memory usage: 362.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge dispatch and price data on their common keys\n",
    "df = pd.merge(dispatch_df, price_df, on=['SETTLEMENTDATE', 'REGIONID'], how='outer')\n",
    "\n",
    "# Merge weather data. Weather is not region-specific in the source, so we merge on timestamp only.\n",
    "# This broadcasts the same weather data across all regions for a given timestamp.\n",
    "df = pd.merge(df, weather_df, left_on='SETTLEMENTDATE', right_on='DATE_TIME_HH', how='left')\n",
    "df = df.drop(columns=['DATE_TIME_HH'])\n",
    "\n",
    "# Merge date dimension data\n",
    "df['date_only'] = df['SETTLEMENTDATE'].dt.date\n",
    "date_dim_df['date_only'] = date_dim_df['ADJ_DATE'].dt.date\n",
    "df = pd.merge(df, date_dim_df, on='date_only', how='left')\n",
    "df = df.drop(columns=['date_only', 'ADJ_DATE'])\n",
    "\n",
    "print(f\"Merged DataFrame shape: {df.shape}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handle Missing Values and Finalize\n",
    "\n",
    "The merges (especially the 'outer' and 'left' joins) may have introduced missing values. We will now set the timestamp as the index, sort the data, and then apply a robust interpolation strategy for the numeric weather features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
      "/var/folders/2g/gmhqyc3x347fffbcnqypjb100000gn/T/ipykernel_6940/1759621296.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled. Final DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 214495 entries, 2023-01-01 00:00:00 to 2025-06-13 04:00:00\n",
      "Data columns (total 26 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   REGIONID                214495 non-null  object \n",
      " 1   TOTALDEMAND             214495 non-null  float64\n",
      " 2   AVAILABLEGENERATION     214495 non-null  float64\n",
      " 3   AVAILABLELOAD           214495 non-null  float64\n",
      " 4   DISPATCHABLEGENERATION  214495 non-null  float64\n",
      " 5   DISPATCHABLELOAD        214495 non-null  float64\n",
      " 6   NETINTERCHANGE          214495 non-null  float64\n",
      " 7   INITIALSUPPLY           214495 non-null  float64\n",
      " 8   CLEAREDSUPPLY           214495 non-null  float64\n",
      " 9   RRP                     214495 non-null  float64\n",
      " 10  IS_WORKDAY              214495 non-null  object \n",
      " 11  IS_SCHOOL_HOLIDAY       214495 non-null  object \n",
      " 12  AIR_TEMP                214495 non-null  float64\n",
      " 13  HUMIDITY                214495 non-null  float64\n",
      " 14  DEW_POINT_TEMP          214495 non-null  float64\n",
      " 15  WIND_SPEED              214495 non-null  float64\n",
      " 16  PV_POWER                214495 non-null  float64\n",
      " 17  APPARENT_TEMP           214495 non-null  float64\n",
      " 18  IS_CALCULATED_APP_TEMP  214495 non-null  object \n",
      " 19  PV_POWER_MISSING        214495 non-null  object \n",
      " 20  DAY_TYPE_QLD            214495 non-null  object \n",
      " 21  QLD_PUBLIC_HOLIDAY      214495 non-null  bool   \n",
      " 22  TAS_PUBLIC_HOLIDAY      214495 non-null  bool   \n",
      " 23  NSW_PUBLIC_HOLIDAY      214495 non-null  bool   \n",
      " 24  VIC_PUBLIC_HOLIDAY      214495 non-null  bool   \n",
      " 25  IS_QLD_SCHOOL_HOLIDAY   214495 non-null  bool   \n",
      "dtypes: bool(5), float64(15), object(6)\n",
      "memory usage: 37.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Set and sort the index\n",
    "df = df.set_index('SETTLEMENTDATE').sort_index()\n",
    "\n",
    "# The weather data was only for one region. We will forward/backward fill within each region group.\n",
    "numeric_cols_to_fill = ['AIR_TEMP', 'HUMIDITY', 'DEW_POINT_TEMP', 'WIND_SPEED', 'APPARENT_TEMP']\n",
    "\n",
    "# We group by region to prevent data from one region leaking into another during interpolation\n",
    "df[numeric_cols_to_fill] = df.groupby('REGIONID')[numeric_cols_to_fill].transform(\n",
    "    lambda x: x.interpolate(method='time').fillna(method='ffill').fillna(method='bfill')\n",
    ")\n",
    "\n",
    "# Drop any remaining rows with NaNs (could be from outer joins where a match was not found)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(\"Missing values handled. Final DataFrame info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Processed Data\n",
    "\n",
    "We will save the final, cleaned DataFrame to a `.parquet` file. Parquet is a columnar storage format that is highly efficient for analytics and preserves data types, which prevents issues when loading the data in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to: ../processed/master_dataset.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGIONID</th>\n",
       "      <th>TOTALDEMAND</th>\n",
       "      <th>AVAILABLEGENERATION</th>\n",
       "      <th>AVAILABLELOAD</th>\n",
       "      <th>DISPATCHABLEGENERATION</th>\n",
       "      <th>DISPATCHABLELOAD</th>\n",
       "      <th>NETINTERCHANGE</th>\n",
       "      <th>INITIALSUPPLY</th>\n",
       "      <th>CLEAREDSUPPLY</th>\n",
       "      <th>RRP</th>\n",
       "      <th>...</th>\n",
       "      <th>PV_POWER</th>\n",
       "      <th>APPARENT_TEMP</th>\n",
       "      <th>IS_CALCULATED_APP_TEMP</th>\n",
       "      <th>PV_POWER_MISSING</th>\n",
       "      <th>DAY_TYPE_QLD</th>\n",
       "      <th>QLD_PUBLIC_HOLIDAY</th>\n",
       "      <th>TAS_PUBLIC_HOLIDAY</th>\n",
       "      <th>NSW_PUBLIC_HOLIDAY</th>\n",
       "      <th>VIC_PUBLIC_HOLIDAY</th>\n",
       "      <th>IS_QLD_SCHOOL_HOLIDAY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SETTLEMENTDATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>NSW1</td>\n",
       "      <td>6912.65</td>\n",
       "      <td>11165.60657</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6369.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-542.69</td>\n",
       "      <td>6958.41699</td>\n",
       "      <td>6933.16</td>\n",
       "      <td>93.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NWD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>QLD1</td>\n",
       "      <td>5804.16</td>\n",
       "      <td>8302.43201</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5784.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.28</td>\n",
       "      <td>5832.15381</td>\n",
       "      <td>5804.20</td>\n",
       "      <td>96.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NWD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>SA1</td>\n",
       "      <td>1443.28</td>\n",
       "      <td>2893.74605</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1466.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.84</td>\n",
       "      <td>1454.43481</td>\n",
       "      <td>1442.92</td>\n",
       "      <td>82.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NWD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>TAS1</td>\n",
       "      <td>988.72</td>\n",
       "      <td>2322.76831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1443.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>454.35</td>\n",
       "      <td>1005.17883</td>\n",
       "      <td>1006.79</td>\n",
       "      <td>73.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NWD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>VIC1</td>\n",
       "      <td>4740.34</td>\n",
       "      <td>8592.02719</td>\n",
       "      <td>125.0</td>\n",
       "      <td>4882.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.69</td>\n",
       "      <td>4806.31689</td>\n",
       "      <td>4758.98</td>\n",
       "      <td>84.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NWD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               REGIONID  TOTALDEMAND  AVAILABLEGENERATION  AVAILABLELOAD  \\\n",
       "SETTLEMENTDATE                                                             \n",
       "2023-01-01         NSW1      6912.65          11165.60657           57.0   \n",
       "2023-01-01         QLD1      5804.16           8302.43201           75.0   \n",
       "2023-01-01          SA1      1443.28           2893.74605          147.0   \n",
       "2023-01-01         TAS1       988.72           2322.76831            0.0   \n",
       "2023-01-01         VIC1      4740.34           8592.02719          125.0   \n",
       "\n",
       "                DISPATCHABLEGENERATION  DISPATCHABLELOAD  NETINTERCHANGE  \\\n",
       "SETTLEMENTDATE                                                             \n",
       "2023-01-01                     6369.96               0.0         -542.69   \n",
       "2023-01-01                     5784.88               0.0          -19.28   \n",
       "2023-01-01                     1466.12               0.0           22.84   \n",
       "2023-01-01                     1443.07               0.0          454.35   \n",
       "2023-01-01                     4882.03               0.0          141.69   \n",
       "\n",
       "                INITIALSUPPLY  CLEAREDSUPPLY    RRP  ... PV_POWER  \\\n",
       "SETTLEMENTDATE                                       ...            \n",
       "2023-01-01         6958.41699        6933.16  93.80  ...      0.0   \n",
       "2023-01-01         5832.15381        5804.20  96.07  ...      0.0   \n",
       "2023-01-01         1454.43481        1442.92  82.92  ...      0.0   \n",
       "2023-01-01         1005.17883        1006.79  73.45  ...      0.0   \n",
       "2023-01-01         4806.31689        4758.98  84.20  ...      0.0   \n",
       "\n",
       "               APPARENT_TEMP  IS_CALCULATED_APP_TEMP  PV_POWER_MISSING  \\\n",
       "SETTLEMENTDATE                                                           \n",
       "2023-01-01              23.3                    True             False   \n",
       "2023-01-01              23.3                    True             False   \n",
       "2023-01-01              23.3                    True             False   \n",
       "2023-01-01              23.3                    True             False   \n",
       "2023-01-01              23.3                    True             False   \n",
       "\n",
       "                DAY_TYPE_QLD  QLD_PUBLIC_HOLIDAY  TAS_PUBLIC_HOLIDAY  \\\n",
       "SETTLEMENTDATE                                                         \n",
       "2023-01-01               NWD               False               False   \n",
       "2023-01-01               NWD               False               False   \n",
       "2023-01-01               NWD               False               False   \n",
       "2023-01-01               NWD               False               False   \n",
       "2023-01-01               NWD               False               False   \n",
       "\n",
       "                NSW_PUBLIC_HOLIDAY VIC_PUBLIC_HOLIDAY IS_QLD_SCHOOL_HOLIDAY  \n",
       "SETTLEMENTDATE                                                               \n",
       "2023-01-01                   False              False                 False  \n",
       "2023-01-01                   False              False                 False  \n",
       "2023-01-01                   False              False                 False  \n",
       "2023-01-01                   False              False                 False  \n",
       "2023-01-01                   False              False                 False  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_path = processed_dir / 'master_dataset.parquet'\n",
    "df.to_parquet(output_path)\n",
    "\n",
    "print(f\"Processed data saved to: {output_path}\")\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
